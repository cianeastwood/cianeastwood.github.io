<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>Cian Eastwood</title>
  
  <meta name="author" content="Cian Eastwood">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=0">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="stylesheet" href="font-awesome/css/font-awesome.min.css">
  <link rel="stylesheet" href="academicons/css/academicons.min.css">
  <link rel="icon" type="image/png" href="images/favicon.ico">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr style="padding:0px">
            <td class="mobile-td" style="padding:2.5%;width:63%;vertical-align:middle">
              <p class="mobile-p" style="text-align:center">
                <name>Cian Eastwood</name>
              </p>
              <div class="div-only-mobile" style="padding:2.5%;width:40%;max-width:40%;margin:auto">
                <a target="_blank" href="images/ce_profile.png"><img src="images/ce_profile.png" alt="Profile photo" img="" style="width:100%;max-width:100%"></a>
              </div>
              <p>
                I am machine learning PhD student at the University of Edinburgh (supervised by
                <a href="https://homepages.inf.ed.ac.uk/ckiw/">Chris Williams</a>) and the 
                Max Planck Institute for Intelligent Systems, Tübingen (supervised by <a href="https://www.is.mpg.de/person/bs">Bernhard
                  Schölkopf</a>).
              </p>
              <p>
                During my PhD, I have spent time at <a href="https://research.google/">Google</a> (Brain/DeepMind, London), <a href="https://ai.meta.com/">Meta</a> (FAIR Labs, New York) and <a href="https://research.atspotify.com/2023/04/gaining-confidence-in-synthetic-control-causal-inference-with-sensitivity-analysis/">Spotify</a> (Causal Inference Lab, London).
              </p>
              <script type="text/javascript">
                .icon
              </script>
              <p style="text-align:center">
                <div class="icons" style="text-align:center" t>
                <a href="mailto:c.eastwood@ed.ac.uk"><i class="fa fa-envelope fa-fw"></i></a> &nbsp&nbsp/&nbsp&nbsp
                <a href="data/Cian-Eastwood-CV.pdf"><i class="ai ai-cv ai-lg"></i></a> &nbsp&nbsp/&nbsp&nbsp
                <a href="https://scholar.google.com/citations?hl=en&user=p7VFLEIAAAAJ"><i class="ai ai-google-scholar ai-lg"></i></a> &nbsp&nbsp/&nbsp&nbsp
                <a href="https://twitter.com/CianEastwood"><i class="fa fa-twitter fa-lg"></i></a> &nbsp&nbsp/&nbsp&nbsp
                <a href="https://github.com/CianEastwood" itemprop="SameAs"><i class="fa fa-github fa-lg"></i></a>
                </div>
              </p>
            </td>
            <td class="desk" style="padding:2.5%;width:40%;max-width:40%;text-align: center;">
              <a href="images/ce_profile.png" target="_blank"><img style="width:100%;max-width:100%" alt="profile photo" src="images/ce_profile.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px; padding-top:20px; padding-bottom:10px; width:100%; vertical-align:middle">
              <heading>Research</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px; padding-top:0px; padding-bottom:0px; width:100%; vertical-align:middle">
              <p>
                My research interests lie at the intersection of <i>distribution shift</i>,
                  <i>representation learning</i> and <i>causality</i>. This often involves exploring different ways to
                  deal with distribution shift such as domain generalization, domain adaptation, and causal/disentangled
                  representation learning. I am also excited by methods for causal structure learning and (Bayesian)
                  experimental design, and how they may be used to accelerate scientific discoveries.
              </p>

            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px; padding-top:60px; padding-bottom:10px; width:100%; vertical-align:middle">
              <heading>News</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px; padding-top:0px; padding-bottom:10px; width:100%; vertical-align:middle">
              <ul>
                <li>09/2023: Our paper <a href="https://arxiv.org/abs/2307.09933">"Spuriosity Didn't Kill the Classifier: Using Invariant Predictions to Harness Spurious Features"</a> was accepted to <b>NeurIPS 2023</b>.</li>
                <li>08/2023: Excited to spend 4 months (September--December) at <a href="https://research.google/teams/brain/">Google Brain/DeepMind</a> as a Student Researcher.</li>
                <li>07/2023: We are organising a <a href="https://crl-workshop.github.io/">Workshop on Causal Representation Learning at NeurIPS 2023</a>!</li>
                <li>06/2023: Excited to spend 3 months (June--August) at <a href="https://research.atspotify.com/machine-learning/">Spotify Research</a> (London, Causal Inference Lab), as a Research Scientist Intern.</li>
                <li>01/2023: Our paper <a href="https://arxiv.org/abs/2210.00364">"DCI-ES: An Extended Disentanglement Framework with Connections to
                      Identifiability"</a> was accepted to <b>ICLR 2023</b>.</li>
                  <!-- <li>12/2022: I gave a talk on "Distribution shift and causal/disentangled representations" to the <a href="https://wp.nyu.edu/cilvr/">Computational Intelligence, Vision, and Robotics Lab</a> (New York University).</li>
                 <li>11/2022: I gave a talk on our Quantile Risk Minimization paper to <a href="http://web.math.ku.dk/~peters/">Jonas Peter's</a> group (University of Copenhagen).</li>
                 <li>11/2022: I gave talks entitled "Shift Happens: How can we best prepare?" to the groups of <a href="http://www.mit.edu/~xboix/">Xavier Boix</a> (MIT) and <a href="https://www.krikamol.org/">Krikamol Muandet</a> (CIPSA).</li> -->
                 <li>10/2022: Selected as a <a href="https://neurips.cc/Conferences/2022/ProgramCommittee">Top Reviewer</a> for NeurIPS 2022.</li>
                 <li>09/2022: Our paper <a href="https://arxiv.org/abs/2207.09944">"Probable Domain Generalization via Quantile Risk Minimization"</a> was accepted to <b>NeurIPS 2022</b>.</li>
                 <!-- <li>07/2022: Our paper "On the DCI Framework for Evaluating Disentangled Representations: Extensions and Connections to Identifiability" was accepted to the UAI 2022 workshop on <a href="https://crl-uai-2022.github.io/">Causal Representation Learning</a>.</li> -->
                 <li>04/2022: Selected as a <a href="https://iclr.cc/Conferences/2022/Reviewers">"Highlighted Reviewer"</a> of ICLR 2022.</li>
                 <!-- <li>03/2022: Our paper "Align-Deform-Subtract: An Interventional Framework for Explaining Object Differences" was accepted to the ICLR 2022 workshop on <a href="https://objects-structure-causality.github.io/">Objects, Structure and Causality</a>.</li>  -->
                 <li>02/2022: Excited to spend 4 months (August--December) at <a href="https://ai.facebook.com/">Meta AI</a>, New York, as an AI Research Intern.</li>
                 <!-- <li>01/2022: Our paper "Source-Free Adaptation to Measurement Shift via Bottom-Up Feature Restoration" was accepted to <b>ICLR 2022 (Spotlight)</b>. </li>
                 <li>12/2021: Our paper "Unit-Level Surprise in Neural Networks" won the <a href="https://i-cant-believe-its-not-better.github.io/neurips2021/awards/">Didactic Paper Award</a> at the NeurIPS 2021 workshop I Can't Believe it's Not Better and was accepted for publication in PMLR. </li>
                 <li>10/2021: Our paper "Unit-Level Surprise in Neural Networks" was accepted to the NeurIPS 2021 workshop <a href="https://i-cant-believe-its-not-better.github.io/neurips2021/">I Can't Believe It's Not Better!</a> <b>(Spotlight)</b>.</li>
                 <li>04/2021: Started my <a href="https://ellis.eu/">ELLIS</a> exchange at the <a href="https://ei.is.tuebingen.mpg.de/">Max Planck Institute for Intelligent Systems, Tübingen</a> with <a href="https://www.is.mpg.de/person/bs">Bernhard Sch&ouml;lkopf</a> to work on causal representation learning.</li>
                <li>09/2020: Our paper "Learning Object-Centric Representations of Multi-Object Scenes from Multiple Views" was accepted to <b>NeurIPS 2020 (Spotlight)</b>.</li>
                <li>07/2020: Attended the <a href="http://mlss.tuebingen.mpg.de/2020/">Machine Learning Summer School (MLSS) 2020</a>.</li> -->
             </ul>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px; padding-top:60px; padding-bottom:10px; width:100%; vertical-align:middle">
              <heading>Publications</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
          <tr class="grid-2" onmouseout="ssl_stop()" onmouseover="ssl_start()">
              <td class="grid-l">
                <div class="one">
                  <div class="two" id='ssl_1'>
                    <img id="ssl" src='images/ssl_disent_1e.svg' width="100%">
                  </div>
                  <div class="two" id='ssl_2'>
                    <img src='images/ssl_disent_2e.svg' width="100%">
                  </div>
                </div>
                <script type="text/javascript">
                  function ssl_start() {
                    document.getElementById('ssl_1').style.opacity = "1";
                    document.getElementById('ssl_2').style.opacity = "0";
                  }
  
                  function ssl_stop() {
                    document.getElementById('ssl_1').style.opacity = "0";
                    document.getElementById('ssl_2').style.opacity = "1";
                  }
                  ssl_stop()
                </script>
              </td>
              <td id="ssl_pp" class="grid-r">
                <a href="https://arxiv.org/abs/2311.08815">
                  <papertitle>Self-Supervised Disentanglement by Leveraging Structure in Data Augmentations</papertitle>
                </a>
                <p class="names">
                <strong>C Eastwood</strong>,
                <a href="https://sites.google.com/view/julius-von-kuegelgen/home">J von Kügelgen</a>,
                <a href="https://linusericsson.github.io/">L Ericsson</a>,
                <a href="https://dianebouchacourt.github.io/">D Bouchacourt</a>,
                <a href="https://mila.quebec/en/person/pascal-vincent/">P Vincent</a>,
                <a href="https://www.is.mpg.de/~bs">B Sch&ouml;lkopf</a>,
                <a href="https://markibrahim.me/">M Ibrahim</a>
                </p>
          <em class="journal">Preprint, 2023</em>
            <p class="journal">
            </p>
                <p class="abstract"> We propose a new self-supervised learning framework which uses data augmentations to 
                  disentangle "style" attributes of the data, rather than discard them.</p>
                <p class="abstract">(Previously @ NeurIPS 2023 workshops on <a href="https://openreview.net/forum?id=KVqyyPvK9H">Self-Supervised Learning</a> 
                  and <a href="https://openreview.net/forum?id=JoISqbH8vl">Causal Representation Learning</a>)</p>
              </td>
          </tr>
          <tr class="grid-2" onmouseout="sfb_stop()" onmouseover="sfb_start()">
              <td class="grid-l">
                <div class="one">
                  <div class="two" id='sfb_1'>
                    <img id="sfb" src='images/sfb_2.svg' width="100%">
                  </div>
                  <div class="two" id='sfb_2'>
                    <img src='images/sfb_1.svg' width="100%">
                  </div>
                </div>
                <script type="text/javascript">
                  function sfb_start() {
                    document.getElementById('sfb_1').style.opacity = "1";
                    document.getElementById('sfb_2').style.opacity = "0";
                  }
  
                  function sfb_stop() {
                    document.getElementById('sfb_1').style.opacity = "0";
                    document.getElementById('sfb_2').style.opacity = "1";
                  }
                  sfb_stop()
                </script>
              </td>
              <td id="sfb_pp" class="grid-r">
                <a href="https://arxiv.org/abs/2307.09933">
                  <papertitle>Spuriosity Didn't Kill the Classifier: Using Invariant Predictions to Harness Spurious Features</papertitle>
                </a>
                <p class="names">
                <strong>C Eastwood</strong>*,
                <a href="https://sss1.github.io/">S Singh</a>*,
                <a href="https://andreinicolicioiu.github.io/">A Nicolicioiu</a>,
                <a href="https://jimimvp.github.io/">M Vlastelica</a>,
                <a href="https://sites.google.com/view/julius-von-kuegelgen/home">J von Kügelgen</a>,
                <a href="https://www.is.mpg.de/~bs">B Sch&ouml;lkopf</a>
                </p>
          <em class="journal">NeurIPS 2023</em>
            <p class="journal">
            <a href="https://github.com/cianeastwood/sfb">Code</a>
            </p>
                <p class="abstract"> We show that "spurious" features need not be discarded for robustness, but can instead be 
                  <em>safely harnessed without test-domain labels</em> by using invariant predictions as pseudo-labels.</p>
                <p class="abstract">(<a href="https://openreview.net/forum?id=cvj2FdS8mm">Previously</a> @ ICML 2023 
                  <a href="https://sites.google.com/view/scis-workshop-23">Spurious Correlations Workshop</a>)</p>
              </td>
          </tr>
          <tr class="grid-2" onmouseout="dcies_stop()" onmouseover="dcies_start()">
            <td class="grid-l">
              <div class="one">
                <div class="two" id='dcies_1'>
                  <img id="dcies" src='images/lc_curve_n_2.svg' width="100%">
                </div>
                <div class="two" id='dcies_2'>
                  <img src='images/lc_curve_n.svg' width="100%">
                </div>
              </div>
              <script type="text/javascript">
                function dcies_start() {
                  document.getElementById('dcies_1').style.opacity = "1";
                  document.getElementById('dcies_2').style.opacity = "0";
                }

                function dcies_stop() {
                  document.getElementById('dcies_1').style.opacity = "0";
                  document.getElementById('dcies_2').style.opacity = "1";
                }
                dcies_stop()
              </script>
            </td>
            <td id="dcies_pp" class="grid-r">
              <a href="https://arxiv.org/abs/2210.00364">
                <papertitle>DCI-ES: An Extended Disentanglement Framework with Connections to Identifiability</papertitle>
              </a>
              <p class="names">
              <strong>C Eastwood</strong>*,
              <a href="https://andreinicolicioiu.github.io/">A Nicolicioiu</a>*,
              <a href="https://sites.google.com/view/julius-von-kuegelgen/home">J von Kügelgen</a>*,
              <a href="https://arminkekic.com/">A Kekić</a>,
              <a href="https://ei.is.mpg.de/person/ftraeuble">F Träuble</a>,
              <a href="https://addtt.github.io/">A Dittadi</a>,
              <a href="https://www.is.mpg.de/~bs">B Sch&ouml;lkopf</a>
              </p>
        <em class="journal">ICLR 2023</em>
              <p class="journal">
              <a href="https://github.com/andreinicolicioiu/DCI-ES">Code</a>
              </p>
              <p class="abstract">We extend the <a href="https://homepages.inf.ed.ac.uk/s1668298/#dci">DCI framework</a> and connect it to identifiability. 
                The key idea is to quantify the "explicitness" of a representation by the <i>functional capacity required to use it</i>.</p>
              <p class="abstract">(<a href="https://openreview.net/forum?id=KiMUlK8GNG5">Previously</a> @ UAI 2022 <a href="https://crl-uai-2022.github.io/">Causal Repr. Learning Workshop</a>)</p>
            </td>
          </tr>
          <tr class="grid-2" onmouseout="qrm_stop()" onmouseover="qrm_start()">
            <td class="grid-l">
              <div class="one">
                <div class="two" id='qrm_1'>
                  <img id="qrm" src='images/qr_2.svg' width="100%">
                </div>
                <div class="two" id='qrm_2'>
                  <img src='images/qr.svg' width="100%">
                </div>
              </div>
              <script type="text/javascript">
                function qrm_start() {
                  document.getElementById('qrm_1').style.opacity = "1";
                  document.getElementById('qrm_2').style.opacity = "0";
                }

                function qrm_stop() {
                  document.getElementById('qrm_1').style.opacity = "0";
                  document.getElementById('qrm_2').style.opacity = "1";
                }
                qrm_stop()
              </script>
            </td>
            <td id="pdg_qrm" class="grid-r">
              <a href="https://arxiv.org/abs/2207.09944">
                <papertitle>Probable Domain Generalization via Quantile Risk Minimization</papertitle>
              </a>
              <p class="names">
              <strong>C Eastwood</strong>*,
              <a href="https://arobey1.github.io/">A Robey</a>*,
              <a href="https://sss1.github.io/">S Singh</a>,
              <a href="https://sites.google.com/view/julius-von-kuegelgen/home">J von Kügelgen</a>,
              <a href="https://www.seas.upenn.edu/~hassani/">H Hassani</a>,
              <a href="https://www.georgejpappas.org/">G J Pappas</a>,
              <a href="https://www.is.mpg.de/~bs">B Sch&ouml;lkopf</a>
              <!-- <strong>Cian Eastwood</strong>*,
              <a href="https://arobey1.github.io/">Alexander Robey</a>*,
              <a href="https://sss1.github.io/">Shashank Singh</a>,
              <a href="https://sites.google.com/view/julius-von-kuegelgen/home">Julius von Kügelgen</a>,
              <a href="https://www.seas.upenn.edu/~hassani/">Hamed Hassani</a>,
              <a href="https://www.georgejpappas.org/">George J. Pappas</a>,
              <a href="https://www.is.mpg.de/~bs">Bernhard Sch&ouml;lkopf</a> -->
              </p>
        <em class="journal">NeurIPS 2022</em>
              <p class="journal">
              <a href="https://github.com/cianeastwood/qrm">Code</a>
              /
              <a href="https://slideslive.com/38991025/probable-domain-generalization-via-quantile-risk-minimization?ref=speaker-50036">Video</a>
              </p>
              <p class="abstract">We propose QRM for learning predictors that generalize with a desired proability <span style="font-family: Symbol">α</span>, provide the conditions
                under which QRM recovers the causal predictor as <span style="font-family: Symbol">α</span> &rarr; 1, and argue for more holistic evaluation protocols in domain generalization.
            </td>
          </tr>
          <tr class="grid-2" onmouseout="ads_stop()" onmouseover="ads_start()">
            <td class="grid-l">
              <div class="one">
                <div class="two" id='ads_1'>
                  <img id="ads" src='images/ads_2-cropped.svg' width="100%">
                </div>
                <div class="two" id='ads_2'>
                  <img src='images/ads_1-cropped.svg' width="100%">
                </div>
              </div>
              <script type="text/javascript">
                function ads_start() {
                  document.getElementById('ads_1').style.opacity = "1";
                  document.getElementById('ads_2').style.opacity = "0";
                }

                function ads_stop() {
                  document.getElementById('ads_1').style.opacity = "0";
                  document.getElementById('ads_2').style.opacity = "1";
                }
                ads_stop()
              </script>
            </td>
            <td class="grid-r">
              <a href="https://arxiv.org/abs/2203.04694">
                <papertitle>Align-Deform-Subtract: An Interventional Framework for Explaining Object Differences</papertitle>
              </a>
              <p class="names">
              <strong>C Eastwood</strong>*,
              <a href="https://www.inf.ed.ac.uk/people/students/Nanbo_Li.html">N Li</a>*,
              <a href="https://homepages.inf.ed.ac.uk/ckiw/">CKI Williams</a>
              </p>
        <em class="journal">ICLR 2022 Workshop: Objects, Structure and Causality</em>
              <br>
              <p></p>
              <p class="abstract">We propose a framework for explaining object-image differences in terms of the underlying object properties (e.g., pose, shape, appearance).
                <em>Main idea:</em> view image-space semantic alignments as counterfactual interventions on the underlying properties.</p>
              <!--<p>*equal contribution</p>-->
            </td>
          </tr>
          <tr class="grid-2" onmouseout="bufr_stop()" onmouseover="bufr_start()">
            <td class="grid-l">
              <div class="one">
                <div class="two" id='bufr_1'>
                  <img id="bufr" src='images/ds_2.svg' width="220px">
                </div>
                <div class="two" id='bufr_2'>
                  <img src='images/ds_1.svg' width="220px">
                </div>
              </div>
              <script type="text/javascript">
                function bufr_start() {
                  document.getElementById('bufr_1').style.opacity = "1";
                  document.getElementById('bufr_2').style.opacity = "0";
                }

                function bufr_stop() {
                  document.getElementById('bufr_1').style.opacity = "0";
                  document.getElementById('bufr_2').style.opacity = "1";
                }
                bufr_stop()
              </script>
            </td>
            <td id="sfda_ms" class="grid-r">
              <a href="https://arxiv.org/abs/2107.05446">
                <papertitle>Source-Free Adaptation to Measurement Shift via Bottom-Up Feature Restoration</papertitle>
              </a>
              <p class="names">
              <strong>C Eastwood</strong>*,
              <a href="https://ianxmason.github.io/">I Mason</a>*,
              <a href="https://homepages.inf.ed.ac.uk/ckiw/">CKI Williams</a>,
              <a href="https://www.is.mpg.de/~bs">B Sch&ouml;lkopf</a>
              </p>
        <em class="journal">ICLR 2022 (Spotlight)</em>
              <p class="journal">
              <a href="https://github.com/cianeastwood/BUFR">Code</a>
              </p>
              <p class="abstract">We identify a type of distribution shift that can be resolved by restoring the <em>same</em> features rather than learning new ones.
                We restore features in the target domain using: (i) cheap and flexible distribution alignment; (ii) a bottom-up adaptation procedure. </p>
              <!--<p>*equal contribution</p>-->
            </td>
          </tr>
          <tr class="grid-2" onmouseout="unit_stop()" onmouseover="unit_start()">
            <td class="grid-l">
              <div class="one">
                <div class="two" id='unit_1'>
                  <img id="unit" src='images/uls_new_2.svg' width="220px"> <!-- unit-surprise-2.svg -->
                </div>
                <div class="two" id='unit_2'>
                  <img src='images/uls_new_1.svg' width="220px"> <!-- unit-surprise-1.svg -->
                </div>
              </div>
              <script type="text/javascript">
                function unit_start() {
                  document.getElementById('unit_1').style.opacity = "1";
                  document.getElementById('unit_2').style.opacity = "0";
                }

                function unit_stop() {
                  document.getElementById('unit_1').style.opacity = "0";
                  document.getElementById('unit_2').style.opacity = "1";
                }
                unit_stop()
              </script>
            </td>
            <td class="grid-r">
              <a href="https://openreview.net/forum?id=N5lxfjtUPOS"><papertitle>Unit-Level Surprise in Neural Networks</papertitle></a>
              <p class="names">
              <strong>C Eastwood</strong>*,
              <a href="https://ianxmason.github.io/">I Mason</a>*,
              <a href="https://homepages.inf.ed.ac.uk/ckiw/">CKI Williams</a>
              </p>
        <em class="journal">NeurIPS 2021 Workshop: I Can't Believe it's Not Better (Spotlight, Didactic Award) and PMLR</em>
              <p class="journal">
              <a href="https://github.com/cianeastwood/unit-level-surprise">Code</a>
              /
              <a href="https://slideslive.com/38971932/unitlevel-surprise-in-neural-networks?ref=speaker-50036">Video</a>
              </p>
              <p class="abstract">We argue that unit-level surprise can be useful for: (i) determining which layers/parameters 
                to update for a given distribution shift; and (ii) learning a modularization such that few layers/parameters need be adapted to
                transfer.</p>
              <!--<p>*equal contribution</p>-->
            </td>
          </tr>
          <tr class="grid-2" onmouseout="mm_stop()" onmouseover="mm_start()">
            <td class="grid-l">
              <div class="one">
                <div class="two" id='mm_1'>
                  <img id="mm" src='images/MM2.svg' width="200px">
                </div>
                <div class="two" id='mm_2'>
                  <img src='images/MM1.svg' width="200px">
                </div>
              </div>
              <script type="text/javascript">
                function mm_start() {
                  document.getElementById('mm_1').style.opacity = "1";
                  document.getElementById('mm_2').style.opacity = "0";
                }

                function mm_stop() {
                  document.getElementById('mm_1').style.opacity = "0";
                  document.getElementById('mm_2').style.opacity = "1";
                }
                mm_stop()
              </script>
            </td>
            <td class="grid-r">
              <a href="https://papers.nips.cc/paper/2020/hash/3d9dabe52805a1ea21864b09f3397593-Abstract.html">
                <papertitle>Learning Object-Centric Representations of Multi-Object Scenes from Multiple Views</papertitle>
              </a>
              <p class="names">
              <a href="https://www.inf.ed.ac.uk/people/students/Nanbo_Li.html">N Li</a>,
              <strong>C Eastwood</strong>,
              <a href="https://homepages.inf.ed.ac.uk/rbf/">B Fisher</a>
              </p>
        <em class="journal">NeurIPS 2020 (Spotlight)</em>
              <p class="journal">
              <a href="https://github.com/NanboLi/MulMON">Code</a>
              /
              <a href="https://youtu.be/Og2ic2L77Pw">Video</a>
              </p>
              <p class="abstract">We learn accurate, object-centric representations of 3D scenes by aggregating information from
                multiple 2D views/observations.</p>
            </td>
          </tr>
          <tr class="grid-2" onmouseout="ff_stop()" onmouseover="ff_start()">
            <td class="grid-l">
              <div class="one">
                <div class="two" id='ff_image'>
                  <img src='images/dci_figs_2.svg' width="100%">
                </div>
                <div class="two" id='ff_image_2'>
                  <img src='images/dci_figs_1.svg' width="100%">
                </div>
              </div>
              <script type="text/javascript">
                function ff_start() {
                  document.getElementById('ff_image').style.opacity = "1";
                  document.getElementById('ff_image_2').style.opacity = "0";
                }

                function ff_stop() {
                  document.getElementById('ff_image').style.opacity = "0";
                  document.getElementById('ff_image_2').style.opacity = "1";
                }
                mm_stop()
              </script>
            </td>
            <td id="dci" class="grid-r">
              <a href="https://openreview.net/forum?id=By-7dz-AZ">
                <papertitle>A Framework for the Quantitative Evaluation of Disentangled Representations</papertitle>
              </a>
              <p class="names">
              <strong>C Eastwood</strong>,
              <a href="https://homepages.inf.ed.ac.uk/ckiw/">CKI Williams</a>
              </p>
        <em class="journal">ICLR 2018</em>
              <p class="journal">
              <a href="https://github.com/cianeastwood/qedr">Code</a>
              </p>
              <p class="abstract">We propose a framework and three metrics for quantifying the quality of "disentangled"
                representations&mdash;disentanglement (D), completeness (C) and informativeness (I).</p>
              <p class="abstract">(Spotlight @ NeurIPS 2017 <a href="https://sites.google.com/view/disentanglenips2017">Disentanglement Workshop</a>)</p>
            </td>
          </tr>

        </tbody>
        </table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding-top:100px;">
              <p style="text-align:right;font-size:small;">
                <a href="https://jonbarron.info/">Website source</a>
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
