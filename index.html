<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>Cian Eastwood</title>
  
  <meta name="author" content="Cian Eastwood">
  <!--<meta name="viewport" content="width=800">-->
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=0">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="stylesheet" href="font-awesome/css/font-awesome.min.css">
  <link rel="stylesheet" href="academicons/css/academicons.min.css">
  <link rel="icon" type="image/png" href="images/favicon.ico">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr style="padding:0px">
            <td class="mobile-td" style="padding:2.5%;width:63%;vertical-align:middle">
              <p class="mobile-p" style="text-align:center">
                <name>Cian Eastwood</name>
              </p>
              <div class="div-only-mobile" style="padding:2.5%;width:40%;max-width:40%;margin:auto">
                <a target="_blank" href="images/ce_profile.png"><img src="images/ce_profile.png" alt="Profile photo" img="" style="width:100%;max-width:100%"></a>
              </div>
              <p>
                I am a PhD student with
                <a href="https://homepages.inf.ed.ac.uk/ckiw/">Chris Williams</a> at the University of Edinburgh and
                <a href="https://www.is.mpg.de/person/bs">Bernhard
                  Schölkopf</a> at the Max Planck Institute for Intelligent Systems, Tübingen. Previously, I studied Computer Science (BSc) at the
                National University of Ireland, Maynooth&#8212;spending time
                on exchange at the University of Toronto&#8212;and
                Artificial Intelligence (MSc) at the University of Edinburgh.
              </p>
              <script type="text/javascript">
                .icon
              </script>
              <p style="text-align:center">
                <div class="icons" style="text-align:center" t>
                <!--<a href="mailto:c.eastwood@ed.ac.uk">Email</i></a> &nbsp&nbsp/&nbsp&nbsp
                <a href="data/Cian-Eastwood-CV.pdf">CV</i></a> &nbsp&nbsp/&nbsp&nbsp
                <a href="https://scholar.google.com/citations?hl=en&user=p7VFLEIAAAAJ">Google Scholar</i></a> &nbsp&nbsp/&nbsp&nbsp
                <a href="https://twitter.com/CianEastwood">Twitter</a> &nbsp&nbsp/&nbsp&nbsp
                <a href="https://github.com/CianEastwood" itemprop="SameAs">Github</i></a>-->
                <a href="mailto:c.eastwood@ed.ac.uk"><i class="fa fa-envelope fa-fw"></i></a> &nbsp&nbsp/&nbsp&nbsp
                <a href="data/Cian-Eastwood-CV.pdf"><i class="ai ai-cv ai-lg"></i></a> &nbsp&nbsp/&nbsp&nbsp
                <a href="https://scholar.google.com/citations?hl=en&user=p7VFLEIAAAAJ"><i class="ai ai-google-scholar ai-lg"></i></a> &nbsp&nbsp/&nbsp&nbsp
                <a href="https://twitter.com/CianEastwood"><i class="fa fa-twitter fa-lg"></i></a> &nbsp&nbsp/&nbsp&nbsp
                <a href="https://github.com/CianEastwood" itemprop="SameAs"><i class="fa fa-github fa-lg"></i></a>
                </div>
              </p>
            </td>
            <td class="desk" style="padding:2.5%;width:40%;max-width:40%;text-align: center;">
              <a href="images/ce_profile.png" target="_blank"><img style="width:100%;max-width:100%" alt="profile photo" src="images/ce_profile.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px; padding-top:20px; padding-bottom:10px; width:100%; vertical-align:middle">
              <heading>Research</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px; padding-top:0px; padding-bottom:0px; width:100%; vertical-align:middle">
              <!--<p>
                In the real-world, the conditions under which a model is developed usually differ from those in which it is used. 
                Unfortunately, standard machine learning methods work by ignoring these condition-differences or <i>distribution shifts</i>, leading to catastrophic failures when models move from the lab to the clinic. 
                These failures represent one of the most significant barriers to the real-world deployment of machine learning models, particularly in safety-critical settings.
              </p>-->
              <!--<p>
                Machine learning (ML) methods have achieved remarkable successes on problems with <i>independent and
                identically-distributed </i>(IID) data. However, real-world data is not IID&#8212;environments change,
                experimental conditions shift, new measurement devices are used, and selection biases are introduced.
                Current ML methods struggle when asked to transfer or adapt quickly to such
                <i>out-of-distribution</i> (OOD) data.
              </p>-->
              <!--<p>
               <b>Causality</b> [1] provides a principled mathematical framework to describe the distributional
                differences that arise from the aforementioned system changes. In particular, it supposes that observed
                system changes arise from changes to just a few underlying modules or mechanisms which function
                independently [2].
              </p>-->
              <p>
Broadly, my research interests lie at the intersection of <i>distribution shift</i>, <i>representation learning</i> and <i>causality</i>. This often involves exploring different ways to deal with distribution shift such as domain generalization, domain adaptation, and causal/disentangled representation learning.
I am also excited by methods that combine causal discovery and (Bayesian) experimental design to learn causal relations in an efficient manner.
                <!--<a href="https://www.helmholtz.de/en/health/we-cant-wait-to-combine-our-expertise/">
                understand cellular processes</a>.-->
              </p>
              <!--<p style="line-height:1.5;">
                [1] Pearl, J. (2009). Causality. <i>Cambridge University Press</i>. <br>
                [2] Peters, J., Janzing, D., &amp; Sch&ouml;lkopf, B. (2017). Elements of causal inference: foundations and learning algorithms. <i>MIT Press</i>. <br>
                [3] Sch&ouml;lkopf, B. et al. (2021). Toward causal representation learning. <i>Proceedings of the IEEE</i>, 109(5), 612-634. <br>
                [4] Peters, J., Bühlmann, P., &amp; Meinshausen, N. (2016). Causal inference by using invariant prediction: identification and confidence intervals. Journal of the Royal Statistical Society. Series B (Statistical Methodology), 947-1012.<br>
                [5] Arjovsky, M., Bottou, L., Gulrajani, I., &amp; Lopez-Paz, D. (2019). Invariant risk minimization.
              <i>arXiv:1907.02893</i>.
              </p>-->

            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px; padding-top:60px; padding-bottom:10px; width:100%; vertical-align:middle">
              <heading>News</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px; padding-top:0px; padding-bottom:10px; width:100%; vertical-align:middle">
              <ul>
                 <li>12/2022: I gave a talk on "Distribution shift and causal/disentangled representations" to the <a href="https://wp.nyu.edu/cilvr/">Computational Intelligence, Vision, and Robotics Lab</a> (New York University).</li>
                 <li>11/2022: I gave a talk on our Quantile Risk Minimization paper to <a href="http://web.math.ku.dk/~peters/">Jonas Peter's</a> group (University of Copenhagen).</li>
                 <li>11/2022: I gave talks entitled "Shift Happens: How can we best prepare?" to the groups of <a href="http://www.mit.edu/~xboix/">Xavier Boix</a> (MIT) and <a href="https://www.krikamol.org/">Krikamol Muandet</a> (CIPSA).</li>
                 <li>10/2022: Selected as a <a href="https://neurips.cc/Conferences/2022/ProgramCommittee">Top Reviewer</a> for NeurIPS 2022.</li>
                 <li>09/2022: Our paper "Probable Domain Generalization via Quantile Risk Minimization" was accepted to <b>NeurIPS 2022</b>.</li>
                 <li>07/2022: Our paper "On the DCI Framework for Evaluating Disentangled Representations: Extensions and Connections to Identifiability" was accepted to the UAI 2022 workshop on <a href="https://crl-uai-2022.github.io/">Causal Representation Learning</a>.</li>
                 <li>04/2022: Selected as a <a href="https://iclr.cc/Conferences/2022/Reviewers">"Highlighted Reviewer"</a> of ICLR 2022.</li>
                 <li>03/2022: Our paper "Align-Deform-Subtract: An Interventional Framework for Explaining Object Differences" was accepted to the ICLR 2022 workshop on <a href="https://objects-structure-causality.github.io/">Objects, Structure and Causality</a>.</li> 
                 <li>02/2022: Excited to spend 4 months (August--December) at <a href="https://ai.facebook.com/">Meta AI</a>, New York, as an AI Research Intern.</li>
                 <li>01/2022: Our paper "Source-Free Adaptation to Measurement Shift via Bottom-Up Feature Restoration" was accepted to <b>ICLR 2022 (Spotlight)</b>. </li>
                 <li>12/2021: Our paper "Unit-Level Surprise in Neural Networks" won the <a href="https://i-cant-believe-its-not-better.github.io/neurips2021/awards/">Didactic Paper Award</a> at the NeurIPS 2021 workshop I Can't Believe it's Not Better and was accepted for publication in PMLR. </li>
                 <li>10/2021: Our paper "Unit-Level Surprise in Neural Networks" was accepted to the NeurIPS 2021 workshop <a href="https://i-cant-believe-its-not-better.github.io/neurips2021/">I Can't Believe It's Not Better!</a> <b>(Spotlight)</b>.</li>
                 <li>04/2021: Started my <a href="https://ellis.eu/">ELLIS</a> exchange at the <a href="https://ei.is.tuebingen.mpg.de/">Max Planck Institute for Intelligent Systems, Tübingen</a> with <a href="https://www.is.mpg.de/person/bs">Bernhard Sch&ouml;lkopf</a> to work on causal representation learning.</li>
                <li>09/2020: Our paper "Learning Object-Centric Representations of Multi-Object Scenes from Multiple Views" was accepted to <b>NeurIPS 2020 (Spotlight)</b>.</li>
                <li>07/2020: Attended the <a href="http://mlss.tuebingen.mpg.de/2020/">Machine Learning Summer School (MLSS) 2020</a>.</li>
             </ul>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px; padding-top:60px; padding-bottom:10px; width:100%; vertical-align:middle">
              <heading>Publications</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
          <tr class="grid-2" onmouseout="dcies_stop()" onmouseover="dcies_start()">
            <td class="grid-l">
              <div class="one">
                <div class="two" id='dcies_1'>
                  <img id="dcies" src='images/lc_curve_n_2.svg' width="100%">
                </div>
                <div class="two" id='dcies_2'>
                  <img src='images/lc_curve_n.svg' width="100%">
                </div>
              </div>
              <script type="text/javascript">
                function dcies_start() {
                  document.getElementById('dcies_1').style.opacity = "1";
                  document.getElementById('dcies_2').style.opacity = "0";
                }

                function dcies_stop() {
                  document.getElementById('dcies_1').style.opacity = "0";
                  document.getElementById('dcies_2').style.opacity = "1";
                }
                dcies_stop()
              </script>
            </td>
            <td id="dcies_pp" class="grid-r">
              <a href="https://arxiv.org/abs/2210.00364">
                <papertitle>DCI-ES: An Extended Disentanglement Framework with Connections to Identifiability</papertitle>
              </a>
              <p class="names">
              <strong>Cian Eastwood</strong>*,
              <a href="https://andreinicolicioiu.github.io/">Andrei Nicolicioiu</a>*,
              <a href="https://sites.google.com/view/julius-von-kuegelgen/home">Julius von Kügelgen</a>*,
              <a href="https://arminkekic.com/">Armin Kekić</a>,
              <a href="https://ei.is.mpg.de/person/ftraeuble">Frederik Träuble</a>,
              <a href="https://addtt.github.io/">Andrea Dittadi</a>,
              <a href="https://www.is.mpg.de/~bs">Bernhard Sch&ouml;lkopf</a>
              </p>
        <em class="journal">Preprint</em>
              <br>
              <p></p>
              <p class="abstract">We extend the <a href="https://homepages.inf.ed.ac.uk/s1668298/#dci">DCI framework</a> for evaluating disentangled representations and connect it to identifiability. 
The key idea is to quantify the "explicitness" of a representation by the <i>functional capacity required to use it</i>.</p>
              <!--<p>*equal contribution</p>-->
            </td>
          </tr>
          <tr class="grid-2" onmouseout="qrm_stop()" onmouseover="qrm_start()">
            <td class="grid-l">
              <div class="one">
                <div class="two" id='qrm_1'>
                  <img id="qrm" src='images/qr_2.svg' width="100%">
                </div>
                <div class="two" id='qrm_2'>
                  <img src='images/qr.svg' width="100%">
                </div>
              </div>
              <script type="text/javascript">
                function qrm_start() {
                  document.getElementById('qrm_1').style.opacity = "1";
                  document.getElementById('qrm_2').style.opacity = "0";
                }

                function qrm_stop() {
                  document.getElementById('qrm_1').style.opacity = "0";
                  document.getElementById('qrm_2').style.opacity = "1";
                }
                qrm_stop()
              </script>
            </td>
            <td id="pdg_qrm" class="grid-r">
              <a href="https://arxiv.org/abs/2207.09944">
                <papertitle>Probable Domain Generalization via Quantile Risk Minimization</papertitle>
              </a>
              <p class="names">
              <strong>Cian Eastwood</strong>*,
              <a href="https://arobey1.github.io/">Alexander Robey</a>*,
              <a href="https://sss1.github.io/">Shashank Singh</a>,
              <a href="https://sites.google.com/view/julius-von-kuegelgen/home">Julius von Kügelgen</a>,
              <a href="https://www.seas.upenn.edu/~hassani/">Hamed Hassani</a>,
              <a href="https://www.georgejpappas.org/">George J. Pappas</a>,
              <a href="https://www.is.mpg.de/~bs">Bernhard Sch&ouml;lkopf</a>
              </p>
        <em class="journal">NeurIPS 2022</em>
              <p class="journal">
              <a href="https://github.com/cianeastwood/qrm">Code</a>
              </p>
              <p class="abstract">We propose Quantile Risk Minimization for learning predictors that generalize with probability <span style="font-family: Symbol">&alpha;</span>, recovering the causal predictor as <span style="font-family: Symbol">&alpha; &rarr; 1</span>. <!-- We also introduce a more holistic quantile-focused evaluation protocol for domain generalization.--></p>
              <!--<p>*equal contribution</p>-->
            </td>
          </tr>
          <tr class="grid-2" onmouseout="ads_stop()" onmouseover="ads_start()">
            <td class="grid-l">
              <div class="one">
                <div class="two" id='ads_1'>
                  <img id="ads" src='images/ads_2-cropped.svg' width="100%">
                </div>
                <div class="two" id='ads_2'>
                  <img src='images/ads_1-cropped.svg' width="100%">
                </div>
              </div>
              <script type="text/javascript">
                function ads_start() {
                  document.getElementById('ads_1').style.opacity = "1";
                  document.getElementById('ads_2').style.opacity = "0";
                }

                function ads_stop() {
                  document.getElementById('ads_1').style.opacity = "0";
                  document.getElementById('ads_2').style.opacity = "1";
                }
                ads_stop()
              </script>
            </td>
            <td class="grid-r">
              <a href="https://arxiv.org/abs/2203.04694">
                <papertitle>Align-Deform-Subtract: An Interventional Framework for Explaining Object Differences</papertitle>
              </a>
              <p class="names">
              <strong>Cian Eastwood</strong>*,
              <a href="https://www.inf.ed.ac.uk/people/students/Nanbo_Li.html">Nanbo Li</a>*,
              <a href="https://homepages.inf.ed.ac.uk/ckiw/">Chris Williams</a>
              </p>
        <em class="journal">ICLR 2022 Workshop: Objects, Structure and Causality</em>
              <br>
              <p></p>
              <p class="abstract">We propose a framework for explaining object-image differences in terms of the underlying object properties (e.g. pose, shape, appearance), leveraging image-space semantic alignments as counterfactual interventions on the underlying object properties.</p>
              <!--<p>*equal contribution</p>-->
            </td>
          </tr>
          <tr class="grid-2" onmouseout="lc_stop()" onmouseover="lc_start()">
            <td class="grid-l">
              <div class="one">
                <div class="two" id='lc_1'>
                  <img id="lc" src='images/mlp_probes_adj.png' width="100%">
                </div>
                <div class="two" id='lc_2'>
                  <img src='images/rf_probes_adj.png' width="100%">
                </div>
              </div>
              <script type="text/javascript">
                function lc_start() {
                  document.getElementById('lc_1').style.opacity = "1";
                  document.getElementById('lc_2').style.opacity = "0";
                }

                function lc_stop() {
                  document.getElementById('lc_1').style.opacity = "0";
                  document.getElementById('lc_2').style.opacity = "1";
                }
                lc_stop()
              </script>
            </td>
            <td class="grid-r">
              <a href="https://openreview.net/forum?id=KiMUlK8GNG5">
                <papertitle>On the DCI Framework for Evaluating Disentangled Representations: Extensions and Connections to Identifiability</papertitle>
              </a>
              <p class="names">
              <strong>Cian Eastwood</strong>*,
              <a href="https://andreinicolicioiu.github.io/">Andrei Nicolicioiu</a>*,
              <a href="https://sites.google.com/view/julius-von-kuegelgen/home">Julius von Kügelgen</a>*,
              <a href="https://arminkekic.com/">Armin Kekić</a>,
              <a href="https://ei.is.mpg.de/person/ftraeuble">Frederik Träuble</a>,
              <a href="https://addtt.github.io/">Andrea Dittadi</a>,
              <a href="https://www.is.mpg.de/~bs">Bernhard Sch&ouml;lkopf</a>
              </p>
        <em class="journal">UAI 2022 Workshop: Causal Representation Learning</em>
              <br>
              <p></p>
              <p class="abstract">We connect <a href="https://homepages.inf.ed.ac.uk/s1668298/#dci">DCI disentanglement</a> to identifiability, and propose a new complementary notion of disentanglement based on the <i>functional capacity required to use a representation</i>.</p>
              <!--<p>*equal contribution</p>-->
            </td>
          </tr>
          <tr class="grid-2" onmouseout="bufr_stop()" onmouseover="bufr_start()">
            <td class="grid-l">
              <div class="one">
                <div class="two" id='bufr_1'>
                  <img id="bufr" src='images/ds_2.svg' width="220px">
                </div>
                <div class="two" id='bufr_2'>
                  <img src='images/ds_1.svg' width="220px">
                </div>
              </div>
              <script type="text/javascript">
                function bufr_start() {
                  document.getElementById('bufr_1').style.opacity = "1";
                  document.getElementById('bufr_2').style.opacity = "0";
                }

                function bufr_stop() {
                  document.getElementById('bufr_1').style.opacity = "0";
                  document.getElementById('bufr_2').style.opacity = "1";
                }
                bufr_stop()
              </script>
            </td>
            <td id="sfda_ms" class="grid-r">
              <a href="https://arxiv.org/abs/2107.05446">
                <papertitle>Source-Free Adaptation to Measurement Shift via Bottom-Up Feature Restoration</papertitle>
              </a>
              <p class="names">
              <strong>Cian Eastwood</strong>*,
              <a href="https://ianxmason.github.io/">Ian Mason</a>*,
              <a href="https://homepages.inf.ed.ac.uk/ckiw/">Chris Williams</a>,
              <a href="https://www.is.mpg.de/~bs">Bernhard Sch&ouml;lkopf</a>
              </p>
        <em class="journal">ICLR 2022 (Spotlight)</em>
              <p class="journal">
              <a href="https://github.com/cianeastwood/BUFR">Code</a>
              </p>
              <p class="abstract">We identify a type of domain shift which can be resolved by restoring the *same* features and address it in the source-free setting by using softly-binned histograms to cheaply and flexibly align the marginal feature distributions.</p>
              <!--<p>*equal contribution</p>-->
            </td>
          </tr>
          <tr class="grid-2" onmouseout="unit_stop()" onmouseover="unit_start()">
            <td class="grid-l">
              <div class="one">
                <div class="two" id='unit_1'>
                  <img id="unit" src='images/unit-surprise-2.svg' width="220px">
                </div>
                <div class="two" id='unit_2'>
                  <img src='images/unit-surprise-1.svg' width="220px">
                </div>
              </div>
              <script type="text/javascript">
                function unit_start() {
                  document.getElementById('unit_1').style.opacity = "1";
                  document.getElementById('unit_2').style.opacity = "0";
                }

                function unit_stop() {
                  document.getElementById('unit_1').style.opacity = "0";
                  document.getElementById('unit_2').style.opacity = "1";
                }
                unit_stop()
              </script>
            </td>
            <td class="grid-r">
              <a href="https://openreview.net/forum?id=N5lxfjtUPOS"><papertitle>Unit-Level Surprise in Neural Networks</papertitle></a>
              <p class="names">
              <strong>Cian Eastwood</strong>*,
              <a href="https://ianxmason.github.io/">Ian Mason</a>*,
              <a href="https://homepages.inf.ed.ac.uk/ckiw/">Chris Williams</a>
              </p>
        <em class="journal">NeurIPS 2021 Workshop: I Can't Believe it's Not Better (Spotlight, Didactic Award) and PMLR</em>
              <p class="journal">
              <a href="https://github.com/cianeastwood/unit-level-surprise">Code</a>
              /
              <a href="https://neurips.cc/virtual/2021/workshop/21861#wse-detail-38314">Video</a>
              </p>
              <p class="abstract">We argue that unit-level surprise should be useful for: (i) determining which few parameters should
                update to adapt quickly; and (ii) learning a modularization such that few modules need be adapted to
                transfer.</p>
              <!--<p>*equal contribution</p>-->
            </td>
          </tr>
          <tr class="grid-2" onmouseout="mm_stop()" onmouseover="mm_start()">
            <td class="grid-l">
              <div class="one">
                <div class="two" id='mm_1'>
                  <img id="mm" src='images/MM2.svg' width="200px">
                </div>
                <div class="two" id='mm_2'>
                  <img src='images/MM1.svg' width="200px">
                </div>
              </div>
              <script type="text/javascript">
                function mm_start() {
                  document.getElementById('mm_1').style.opacity = "1";
                  document.getElementById('mm_2').style.opacity = "0";
                }

                function mm_stop() {
                  document.getElementById('mm_1').style.opacity = "0";
                  document.getElementById('mm_2').style.opacity = "1";
                }
                mm_stop()
              </script>
            </td>
            <td class="grid-r">
              <a href="https://papers.nips.cc/paper/2020/hash/3d9dabe52805a1ea21864b09f3397593-Abstract.html">
                <papertitle>Learning Object-Centric Representations of Multi-Object Scenes from Multiple Views</papertitle>
              </a>
              <p class="names">
              <a href="https://www.inf.ed.ac.uk/people/students/Nanbo_Li.html">Nanbo Li</a>,
              <strong>Cian Eastwood</strong>,
              <a href="https://homepages.inf.ed.ac.uk/rbf/">Bob Fisher</a>
              </p>
        <em class="journal">NeurIPS 2020 (Spotlight)</em>
              <p class="journal">
              <a href="https://github.com/NanboLi/MulMON">Code</a>
              /
              <a href="https://youtu.be/Og2ic2L77Pw">Video</a>
              </p>
              <p class="abstract">We learn accurate, object-centric representations of 3D scenes by aggregating information from
                multiple 2D views/observations.</p>
            </td>
          </tr>
          <tr class="grid-2" onmouseout="ff_stop()" onmouseover="ff_start()">
            <td class="grid-l">
              <div class="one">
                <div class="two" id='ff_image'>
                  <img src='images/compl.svg' width="100%">
                </div>
                <div class="two" id='ff_image_2'>
                  <img src='images/dis.svg' width="100%">
                </div>
              </div>
              <script type="text/javascript">
                function ff_start() {
                  document.getElementById('ff_image').style.opacity = "1";
                  document.getElementById('ff_image_2').style.opacity = "0";
                }

                function ff_stop() {
                  document.getElementById('ff_image').style.opacity = "0";
                  document.getElementById('ff_image_2').style.opacity = "1";
                }
                mm_stop()
              </script>
            </td>
            <td id="dci" class="grid-r">
              <a href="https://openreview.net/forum?id=By-7dz-AZ">
                <papertitle>A Framework for the Quantitative Evaluation of Disentangled Representations</papertitle>
              </a>
              <p class="names">
              <strong>Cian Eastwood</strong>,
              <a href="https://homepages.inf.ed.ac.uk/ckiw/">Chris Williams</a>
              </p>
        <em class="journal">ICLR 2018</em>
              <p class="journal">
              <a href="https://github.com/cianeastwood/qedr">Code</a>
              </p>
              <p class="abstract">We propose a framework and three metrics for quantifying the quality of "disentangled"
                representations&mdash;disentanglement (D), completeness (C) and informativeness (I).</p>
              <p class="abstract">(Previously a spotlight presentation @ NeurIPS 2017 <a href="https://sites.google.com/view/disentanglenips2017">disentanglement workshop</a>)</p>
            </td>
          </tr>

        </tbody>
        </table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding-top:100px;">
              <p style="text-align:right;font-size:small;">
                <a href="https://jonbarron.info/">Website source</a>
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
